{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8D surrogate training code\n",
    "\n",
    "This notebook provides an example of the code used to train and evaluate the accuracy of surrogate models for the 8D toy problem discussed in Chapter 4 Section 4.1. \n",
    "\n",
    "Original experiments were run in Google Colab using TPUs. \n",
    "\n",
    "This code is replicated with varying training sizes to produce the full result set. Full code and models are available [here](https://drive.google.com/drive/folders/1J7srZbZPS6UhE43GFXP3Gkd3TmEvT-6f)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 237,
     "status": "ok",
     "timestamp": 1630428975359,
     "user": {
      "displayName": "Chris Mcdonagh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhF-UpNVeUXFvpwslXd-aD8GJZPFHZo2-yZhUuE-A=s64",
      "userId": "16046156616630541706"
     },
     "user_tz": -60
    },
    "id": "N8Ezc5LO_QDV",
    "outputId": "2e1398bb-adcd-450e-fdfe-d3e057ddd17f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "import autograd.numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Lambda, dot, concatenate, PReLU, Dropout, advanced_activations\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import adam_v2\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.metrics import RootMeanSquaredError\n",
    "import concurrent.futures\n",
    "from time import time\n",
    "import gc\n",
    "from scipy import stats\n",
    "from datetime import *\n",
    "from time import time as time1\n",
    "import os\n",
    "import subprocess\n",
    "from google.colab import files\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wYDJk9vd_mCI"
   },
   "outputs": [],
   "source": [
    "# Suppress retracing  and auograph error\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fMvXCMPB_wL8"
   },
   "outputs": [],
   "source": [
    "# Parameters for 10D toy problem\n",
    "nInputDim = 8\n",
    "nOutputDim = 1\n",
    "base_hidden_size = 4\n",
    "nBatchSize = 100\n",
    "\n",
    "# Other parmeters\n",
    "alpha = 0.1\n",
    "beta = 0.2\n",
    "XDIM = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture\n",
    "\n",
    "The neural network used for the 8D toy problem does not model a dynamic process so only involves one architecture. The model has 10 hidden layers, each with $\\eta$ * 4 nodes where $\\eta$ refers to model complexity as described in Chapter 3 Section 3.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bSZTZ6lAkrU1"
   },
   "outputs": [],
   "source": [
    "def make_model(complexity=1, lr=0.001, g_w=0.5):\n",
    "    \"\"\"\"Makes surrogate model.\n",
    "    The weight assigned to the loss function that fits gradients can be set with g_w.\n",
    "    Model complexity integer and determines the number of nodes in each \n",
    "    hidden layer.\n",
    "    \"\"\"\n",
    "    theta = Input(shape=nInputDim)\n",
    "    X = Input(shape=XDIM+1)\n",
    "    concat = concatenate([theta, X])\n",
    "    h1 = Dense(complexity * base_hidden_size, activation=\"tanh\")(concat)\n",
    "    h2 = Dense(complexity * base_hidden_size, activation=\"tanh\")(h1)\n",
    "    h3 = Dense(complexity * base_hidden_size, activation=\"tanh\")(h2)\n",
    "    h4 = Dense(complexity * base_hidden_size, activation=\"tanh\")(h3)\n",
    "    h5 = Dense(complexity * base_hidden_size, activation=\"tanh\")(h4)\n",
    "    h6 = Dense(complexity * base_hidden_size, activation=\"tanh\")(h5)\n",
    "    h7 = Dense(complexity * base_hidden_size, activation=\"tanh\")(h6)\n",
    "    h8 = Dense(complexity * base_hidden_size, activation=\"tanh\")(h7)\n",
    "    h9 = Dense(complexity * base_hidden_size, activation=\"tanh\")(h8)\n",
    "    h10 = Dense(complexity * base_hidden_size, activation=\"tanh\")(h9)\n",
    "    out = Dense(nOutputDim, activation='linear', name='out')(h10)\n",
    "    \n",
    "    grad = Lambda(lambda x: K.gradients(x[0], [x[1]])[0], output_shape=nInputDim)([out, theta])\n",
    "    model = Model(inputs=[theta, X], outputs=[out, grad])\n",
    "    opt = adam_v2.Adam(learning_rate=lr)\n",
    "    model.compile(loss=['mse', 'mse'], optimizer=opt, metrics=[RootMeanSquaredError()], loss_weights=[1-g_w, g_w])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-HbJepQbTm_U"
   },
   "outputs": [],
   "source": [
    "def build_models():\n",
    "    \"\"\" Store models in nested dictionary of the form [time_step][complexity].\n",
    "    \"\"\"\n",
    "    \n",
    "    models_std = defaultdict(dict)\n",
    "    models_grad = defaultdict(dict)\n",
    "\n",
    "    for m in complexity_range:\n",
    "        models_std[m] = make_model(complexity=m, g_w=0)\n",
    "        models_grad[m] = make_model(complexity=m)\n",
    "        \n",
    "    return models_std, models_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TQMlB7YeTm_V"
   },
   "outputs": [],
   "source": [
    "def fit_model(model, theta, X, y, y_grad, complexity, foldername):\n",
    "    \"\"\" Fits the NN models.\n",
    "    Note that when yearIdx=0, prev_output takes value -1 which is incorrect (should be no prev_output), \n",
    "    but it is not used.\n",
    "    \"\"\"\n",
    "    model.fit([theta, X], [y, y_grad], batch_size=nBatchSize, epochs=nEpochs, verbose=0, \n",
    "    use_multiprocessing=True, callbacks=[LearningRateScheduler(lr_time_based_decay)])\n",
    "    \n",
    "    filename = f'{foldername}/8D_example_N{nTrain}_E{nEpochs}_c{complexity}.h5'\n",
    "    model.save(filepath=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d4Rc9WUlTm_W"
   },
   "outputs": [],
   "source": [
    "def train_models(curr_data, models_std, models_grad, foldername):\n",
    "    \n",
    "    simInData_latent = curr_data['simInData_latent']\n",
    "    simInData_X = curr_data['simInData_X']\n",
    "    simOutData = curr_data['simOutData']\n",
    "    simOutData_grad = curr_data['simOutData_grad']\n",
    "    \n",
    "    no_models = len(complexity_range)\n",
    "\n",
    "    foldername_grad = foldername+'_grad'\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=no_models*2) as executor:\n",
    "        future1 = {executor.submit(fit_model, \n",
    "                                  m, \n",
    "                                  simInData_latent.values, simInData_X.values,\n",
    "                                  simOutData.values, simOutData_grad.values, \n",
    "                                  complexity, \n",
    "                                  foldername) \n",
    "                for complexity, m in models_std.items()}\n",
    "\n",
    "        future1 = {executor.submit(fit_model, \n",
    "                                  m, \n",
    "                                  simInData_latent.values, simInData_X.values,\n",
    "                                  simOutData.values, simOutData_grad.values, \n",
    "                                  complexity, \n",
    "                                  foldername_grad) \n",
    "                for complexity, m in models_grad.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "79p0WdjmTm_X"
   },
   "outputs": [],
   "source": [
    "def load_models(foldername):\n",
    "    std_models = defaultdict(dict)\n",
    "    grad_models = defaultdict(dict)\n",
    "    \n",
    "    grad_foldername = foldername + '_grad' \n",
    "\n",
    "    for c in complexity_range:\n",
    "        filename = f'{foldername}/8D_example_N{nTrain}_E{nEpochs}_c{c}.h5'\n",
    "        filename_grad = f'{grad_foldername}/8D_example_N{nTrain}_E{nEpochs}_c{c}.h5'\n",
    "        std_models[c] = load_model(filename)\n",
    "        grad_models[c] = load_model(filename_grad)\n",
    "    return std_models, grad_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4gOfGfXFTm_Z"
   },
   "outputs": [],
   "source": [
    "def gen_preds(train_data, test_data, std_models, grad_models):\n",
    "    \n",
    "    simInData_train_latent = train_data['simInData_latent']\n",
    "    simInData_train_X = train_data['simInData_X']\n",
    "\n",
    "    simInData_test_latent = test_data['simInData_latent']\n",
    "    simInData_test_X = test_data['simInData_X']\n",
    "\n",
    "    simOutData_train = train_data['simOutData'] # Only used for constucting DFs and t0 population\n",
    "    simOutData_test = test_data['simOutData'] # Only used for constucting DFs and t0 population\n",
    "\n",
    "    N_train = len(simInData_train_latent)\n",
    "    N_test = len(simInData_test_latent)\n",
    "\n",
    "    std_preds_train = {}\n",
    "    std_preds_test = {}\n",
    "    \n",
    "    grad_preds_train = {}\n",
    "    grad_preds_test = {}\n",
    "    \n",
    "    for c in complexity_range:\n",
    "        std_preds_train[c] = pd.DataFrame(index=simInData_train_latent.index, columns=range(nOutputDim))\n",
    "        std_preds_test[c] = pd.DataFrame(index=simInData_test_latent.index, columns=range(nOutputDim))\n",
    "        grad_preds_train[c] = pd.DataFrame(index=simInData_train_latent.index, columns=range(nOutputDim))\n",
    "        grad_preds_test[c] = pd.DataFrame(index=simInData_test_latent.index, columns=range(nOutputDim))\n",
    "\n",
    "    for c in complexity_range:\n",
    "\n",
    "        crtModel_std = std_models[c]\n",
    "        crtModel_grad = grad_models[c]\n",
    "\n",
    "        std_preds_train[c].loc[:, 0] = crtModel_std.predict_on_batch([simInData_train_latent.values, \n",
    "                                            simInData_train_X.values])[0].flatten()\n",
    "        std_preds_test[c].loc[:, 0] = crtModel_std.predict_on_batch([simInData_test_latent.values, \n",
    "                                            simInData_test_X.values])[0].flatten()\n",
    "\n",
    "        grad_preds_train[c].loc[:, 0] = crtModel_grad.predict_on_batch([simInData_train_latent.values, \n",
    "                                            simInData_train_X.values])[0].flatten()\n",
    "        grad_preds_test[c].loc[:, 0] = crtModel_grad.predict_on_batch([simInData_test_latent.values, \n",
    "                                            simInData_test_X.values])[0].flatten()\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    return std_preds_train, std_preds_test, grad_preds_train, grad_preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7fPDFPD0Tm_a"
   },
   "outputs": [],
   "source": [
    "# Evaulation metrics\n",
    "def rmse(pred, true):\n",
    "    return np.sqrt(((pred.values - true.values)**2).mean())\n",
    "\n",
    "def corr(pred, true):\n",
    "    return stats.pearsonr(pred.values.flatten(),true.values.flatten())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2e91-i5oTm_b"
   },
   "outputs": [],
   "source": [
    "def evaluate(train_data, test_data, std_preds_train, std_preds_test, grad_preds_train, grad_preds_test):\n",
    "    \n",
    "    simOutData_train = train_data['simOutData'] \n",
    "    simOutData_test = test_data['simOutData']\n",
    "    \n",
    "    std_train_res = defaultdict(dict)\n",
    "    std_test_res = defaultdict(dict)\n",
    "    grad_train_res = defaultdict(dict)\n",
    "    grad_test_res = defaultdict(dict)\n",
    "    \n",
    "    for c in complexity_range:\n",
    "        std_train_res[c]['rmse'] = rmse(std_preds_train[c], simOutData_train)\n",
    "        std_train_res[c]['corr'] = corr(std_preds_train[c], simOutData_train)\n",
    "        \n",
    "        std_test_res[c]['rmse'] = rmse(std_preds_test[c], simOutData_test)\n",
    "        std_test_res[c]['corr'] = corr(std_preds_test[c], simOutData_test)\n",
    "        \n",
    "        grad_train_res[c]['rmse'] = rmse(grad_preds_train[c], simOutData_train)\n",
    "        grad_train_res[c]['corr'] = corr(grad_preds_train[c], simOutData_train)\n",
    "        \n",
    "        grad_test_res[c]['rmse'] = rmse(grad_preds_test[c], simOutData_test)\n",
    "        grad_test_res[c]['corr'] = corr(grad_preds_test[c], simOutData_test)\n",
    "    \n",
    "    \n",
    "    return std_train_res, std_test_res, grad_train_res, grad_test_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xOcoD06XTm_c"
   },
   "outputs": [],
   "source": [
    "def pipe(curr_data, test_data, N_train, foldername, idx):\n",
    "    \n",
    "    print(f'Beginning iteration {idx+1}')\n",
    "    \n",
    "    # Generate seperate foldername for each split to avoid confusion\n",
    "    foldername = foldername + f'_ntrain{N_train}_{idx}'\n",
    "    \n",
    "    # Build models\n",
    "    models_std, models_grad = build_models()\n",
    "    \n",
    "    print(f'Training models for dataset {idx+1}')\n",
    "    t0 = time1()\n",
    "    # Train models and save\n",
    "    train_models(curr_data, models_std, models_grad, foldername)\n",
    "    print(f'Trained models for dataset {idx+1} in {time1() - t0:.02f}s') \n",
    "        \n",
    "    print(f'Loading models for dataset {idx+1}')\n",
    "    # Load models from file\n",
    "    std_models, grad_models = load_models(foldername)\n",
    "    \n",
    "    print(f'Generating predictions for dataset {idx+1}')\n",
    "    # Generate predictions\n",
    "    std_preds_train, std_preds_test, grad_preds_train, grad_preds_test = gen_preds(curr_data, \n",
    "                                                test_data, std_models, grad_models)\n",
    "\n",
    "    std_train_res, std_test_res, grad_train_res, grad_test_res = evaluate(curr_data, test_data, \n",
    "                            std_preds_train, std_preds_test, grad_preds_train, grad_preds_test)\n",
    "    \n",
    "    return std_train_res, std_test_res, grad_train_res, grad_test_res, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FMawjclMTm_d"
   },
   "outputs": [],
   "source": [
    "def run(N_train, no_ds, train_data, test_data, foldername='saved_models_cmplx_tests'):\n",
    "    \n",
    "    N_test = len(test_data['simInData_latent'])\n",
    "\n",
    "    print(f'Beginning process with:')\n",
    "    print(f'-> Epochs: {nEpochs}')\n",
    "    print(f'-> Complexity range: {complexity_range}')\n",
    "    print(f'-> {N_train} training samples')\n",
    "    print(f\"-> {N_test} test samples\")\n",
    "    print(f'-> Averaging {no_ds} datasets')\n",
    "    \n",
    "    # Generate dataframes to store final results in\n",
    "    std_train_rmse = pd.DataFrame(index=complexity_range, columns=range(no_ds))\n",
    "    std_test_rmse = pd.DataFrame(index=complexity_range, columns=range(no_ds))\n",
    "    grad_train_rmse = pd.DataFrame(index=complexity_range, columns=range(no_ds))\n",
    "    grad_test_rmse = pd.DataFrame(index=complexity_range, columns=range(no_ds))\n",
    "    \n",
    "    std_train_corr = pd.DataFrame(index=complexity_range, columns=range(no_ds))\n",
    "    std_test_corr = pd.DataFrame(index=complexity_range, columns=range(no_ds))\n",
    "    grad_train_corr = pd.DataFrame(index=complexity_range, columns=range(no_ds))\n",
    "    grad_test_corr = pd.DataFrame(index=complexity_range, columns=range(no_ds))\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        future_to_res = {executor.submit(pipe, curr_data, test_data, \n",
    "                                        N_train, foldername, i): i \\\n",
    "                         for i, curr_data in train_data.items()}\n",
    "        for i in concurrent.futures.as_completed(future_to_res):\n",
    "            std_train_res, std_test_res, grad_train_res, grad_test_res, idx = i.result()\n",
    "            \n",
    "            for c in complexity_range:\n",
    "                std_train_rmse.loc[c, idx] = std_train_res[c]['rmse']\n",
    "                std_train_corr.loc[c, idx] = std_train_res[c]['corr']\n",
    "                \n",
    "                std_test_rmse.loc[c, idx] = std_test_res[c]['rmse']\n",
    "                std_test_corr.loc[c, idx] = std_test_res[c]['corr']\n",
    "            \n",
    "                grad_train_rmse.loc[c, idx] = grad_train_res[c]['rmse']\n",
    "                grad_train_corr.loc[c, idx] = grad_train_res[c]['corr']\n",
    "                \n",
    "                grad_test_rmse.loc[c, idx] = grad_test_res[c]['rmse']\n",
    "                grad_test_corr.loc[c, idx] = grad_test_res[c]['corr']\n",
    "        \n",
    "        print(f'Completed iteration {int(idx)+1} of {no_ds}')\n",
    "        \n",
    "    # Take averages/stds\n",
    "    std_train_rmse['mean'] = std_train_rmse.mean(axis=1)\n",
    "    std_train_rmse['std'] = std_train_rmse.std(axis=1)\n",
    "    \n",
    "    std_test_rmse['mean'] = std_test_rmse.mean(axis=1)\n",
    "    std_test_rmse['std'] = std_test_rmse.std(axis=1)\n",
    "    \n",
    "    std_train_corr['mean'] = std_train_corr.mean(axis=1)\n",
    "    std_train_corr['std'] = std_train_corr.std(axis=1)\n",
    "    \n",
    "    std_test_corr['mean'] = std_test_corr.mean(axis=1)\n",
    "    std_test_corr['std'] = std_test_corr.std(axis=1)\n",
    "    \n",
    "    grad_train_rmse['mean'] = grad_train_rmse.mean(axis=1)\n",
    "    grad_train_rmse['std'] = grad_train_rmse.std(axis=1)\n",
    "    \n",
    "    grad_test_rmse['mean'] = grad_test_rmse.mean(axis=1)\n",
    "    grad_test_rmse['std'] = grad_test_rmse.std(axis=1)\n",
    "    \n",
    "    grad_train_corr['mean'] = grad_train_corr.mean(axis=1)\n",
    "    grad_train_corr['std'] = grad_train_corr.std(axis=1)\n",
    "    \n",
    "    grad_test_corr['mean'] = grad_test_corr.mean(axis=1)\n",
    "    grad_test_corr['std'] = grad_test_corr.std(axis=1)\n",
    "    \n",
    "    c_time = datetime.now().strftime(\"%Y-%m-%d %H-%M\")\n",
    "    base_string = f'_ntrain{N_train}_ntest{N_test}_nEpoch{nEpochs}_Nruns{no_ds}_{c_time}.csv'\n",
    "    std_filename_train_rmse = f'std_train_rmse'+base_string\n",
    "    std_filename_train_corr = f'std_train_corr'+base_string\n",
    "    \n",
    "    std_filename_test_rmse = f'std_test_rmse'+base_string\n",
    "    std_filename_test_corr = f'std_test_corr'+base_string\n",
    "    \n",
    "    grad_filename_train_rmse = f'grad_train_rmse'+base_string\n",
    "    grad_filename_train_corr = f'grad_train_corr'+base_string\n",
    "    \n",
    "    grad_filename_test_rmse = f'grad_test_rmse'+base_string\n",
    "    grad_filename_test_corr = f'grad_test_corr'+base_string\n",
    "    \n",
    "    res_folder = f'complexity_test_results_ntrain{N_train}_{c_time}'\n",
    "    os.mkdir(res_folder)\n",
    "    std_train_rmse.to_csv(res_folder+'/'+std_filename_train_rmse)\n",
    "    std_train_corr.to_csv(res_folder+'/'+std_filename_train_corr)\n",
    "    std_test_rmse.to_csv(res_folder+'/'+std_filename_test_rmse)\n",
    "    std_test_corr.to_csv(res_folder+'/'+std_filename_test_corr)\n",
    "    \n",
    "    grad_train_rmse.to_csv(res_folder+'/'+grad_filename_train_rmse)\n",
    "    grad_train_corr.to_csv(res_folder+'/'+grad_filename_train_corr)\n",
    "    grad_test_rmse.to_csv(res_folder+'/'+grad_filename_test_rmse)\n",
    "    grad_test_corr.to_csv(res_folder+'/'+grad_filename_test_corr)\n",
    "    \n",
    "    #Zip up results so they can be downloaded.\n",
    "    #subprocess.call([\"zip\", \"-r\", f\"/content/{res_folder}.zip\", f\"/content/{res_folder}\"])\n",
    "    #files.download(f\"/content/{res_folder}.zip\")\n",
    "\n",
    "    print(f'Completed. Saved results to folder {res_folder}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oPm6EL2rUFx7"
   },
   "outputs": [],
   "source": [
    "def sub_sample_data(n_train, no_runs, all_train_data):\n",
    "    \n",
    "    train_data = defaultdict(dict) \n",
    "    for ds in range(no_runs):\n",
    "        np.random.seed(ds)\n",
    "        perm = np.random.permutation(n_train)\n",
    "        train_data[ds]['simInData_latent'] = all_train_data['simInData_latent'].iloc[perm, :].reset_index(drop=True)\n",
    "        train_data[ds]['simInData_X'] = all_train_data['simInData_X'].iloc[perm].reset_index(drop=True)\n",
    "        train_data[ds]['simOutData'] = all_train_data['simOutData'].iloc[perm, :].reset_index(drop=True)\n",
    "        train_data[ds]['simOutData_grad'] = all_train_data['simOutData_grad'].iloc[perm, :].reset_index(drop=True)\n",
    "\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gdXx_7sxiakd"
   },
   "outputs": [],
   "source": [
    "def lr_time_based_decay(epoch, lr):\n",
    "    return lr * 1 / (1 + decay * nEpochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3675,
     "status": "ok",
     "timestamp": 1630428979746,
     "user": {
      "displayName": "Chris Mcdonagh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhF-UpNVeUXFvpwslXd-aD8GJZPFHZo2-yZhUuE-A=s64",
      "userId": "16046156616630541706"
     },
     "user_tz": -60
    },
    "id": "5aZID6qqTerq",
    "outputId": "94ab9de5-2752-4629-8de0-90e18ba73dd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read in dataset.\n"
     ]
    }
   ],
   "source": [
    "# Location of 4D data, generated by function presented in Chaper 3, Section 4.1.1\n",
    "data_folder = '8d_data'\n",
    "\n",
    "all_data_train = {}\n",
    "all_data_test = {}\n",
    "\n",
    "all_data_train['simInData_latent'] = pd.read_csv(f'{data_folder}/x_train_latent.csv', index_col=0)\n",
    "all_data_train['simInData_X'] = pd.read_csv(f'{data_folder}/x_train_X.csv', index_col=0)\n",
    "all_data_train['simOutData'] = pd.read_csv(f'{data_folder}/y_train.csv', index_col=0)\n",
    "all_data_train['simOutData_grad'] = pd.read_csv(f'{data_folder}/y_train_grad.csv', index_col=0)\n",
    "\n",
    "all_data_test['simInData_latent'] = pd.read_csv(f'{data_folder}/x_test_latent.csv', index_col=0)\n",
    "all_data_test['simInData_X'] = pd.read_csv(f'{data_folder}/x_test_X.csv', index_col=0)\n",
    "all_data_test['simOutData'] = pd.read_csv(f'{data_folder}/y_test.csv', index_col=0)\n",
    "print(f'Successfully read in dataset.')\n",
    "# No need to read in test gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pL-25tYT_2Td"
   },
   "outputs": [],
   "source": [
    "# Number of random draws from the training data pool to use\n",
    "n_runs = 5\n",
    "nTrain = 2500\n",
    "\n",
    "train_data_ss = sub_sample_data(nTrain, n_runs, all_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HVK1gNGMUfqg"
   },
   "outputs": [],
   "source": [
    "# Folder to save models to\n",
    "foldername = f'/saved_models_nTrain2500/saved_models_cmplx_tests'\n",
    "nEpochs = 300\n",
    "initial_learning_rate = 0.01\n",
    "decay = initial_learning_rate / nEpochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eZQVkzrfcx8g"
   },
   "outputs": [],
   "source": [
    "complexity_range = [10, 20, 30, 40, 50, 60, 70, 80, 90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "executionInfo": {
     "elapsed": 17722636,
     "status": "ok",
     "timestamp": 1630446702658,
     "user": {
      "displayName": "Chris Mcdonagh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhF-UpNVeUXFvpwslXd-aD8GJZPFHZo2-yZhUuE-A=s64",
      "userId": "16046156616630541706"
     },
     "user_tz": -60
    },
    "id": "7gNXP6y-cUeU",
    "outputId": "3f5bbe9b-d567-4d21-d141-1ae80cb48f93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning process with:\n",
      "-> Epochs: 300\n",
      "-> Complexity range: [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
      "-> 2500 training samples\n",
      "-> 1000 test samples\n",
      "-> Averaging 5 datasets\n",
      "Beginning iteration 1\n",
      "Beginning iteration 2\n",
      "Beginning iteration 3\n",
      "Beginning iteration 4\n",
      "Beginning iteration 5\n",
      "Training models for dataset 1\n",
      "Training models for dataset 3\n",
      "Training models for dataset 2\n",
      "Training models for dataset 5\n",
      "Training models for dataset 4\n",
      "Trained models for dataset 4 in 17514.73s\n",
      "Loading models for dataset 4\n",
      "Generating predictions for dataset 4\n",
      "Trained models for dataset 2 in 17548.82s\n",
      "Loading models for dataset 2\n",
      "Trained models for dataset 1 in 17549.73s\n",
      "Loading models for dataset 1\n",
      "Trained models for dataset 3 in 17549.93s\n",
      "Loading models for dataset 3\n",
      "Trained models for dataset 5 in 17546.88s\n",
      "Loading models for dataset 5\n",
      "Generating predictions for dataset 2\n",
      "Generating predictions for dataset 1\n",
      "Generating predictions for dataset 3\n",
      "Generating predictions for dataset 5\n",
      "Completed iteration 2 of 5\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_bb924196-0997-4be2-87a1-3916d3a4837b\", \"complexity_test_results_ntrain2500_2021-08-31 21-51.zip\", 8283)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed. Saved results to folder complexity_test_results_ntrain2500_2021-08-31 21-51\n",
      "CPU times: user 8h 37min 35s, sys: 42min 37s, total: 9h 20min 12s\n",
      "Wall time: 4h 55min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "run(nTrain, n_runs, train_data_ss, all_data_test, foldername=foldername)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5iClm9A618S6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "complexity_test_nTrain2500.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
